---
title: "Envision App"
summary: "Accessibility-first OCR and visual assistance app for blind and low-vision users."
role: "Engineering Manager & Lead Developer"
tags: ["android", "kotlin", "accessibility", "assistive-tech", "smart-glasses"]
impact:
  - "Shipped and evolved core accessibility-first flows for reading and visual assistance."
  - "Led engineering execution with a focus on reliability, performance, and inclusive UX."
weight: 20
---

**Role:** Engineering Manager & Lead Developer

**Summary:**

Envision is an accessibility-first mobile app that helps blind and low-vision users read text and understand their surroundings using computer vision and machine learning. As Engineering Manager and Lead Developer, I drive Android execution and ship improvements across document reading and recognition workflows with a TalkBack-first UX focus. The product is available on Android and iOS and localized in 7+ languages, using a mix of on-device and cloud models (e.g., ML Kit, Azure, AWS) depending on the capability.

Also built Envision Glasses. The AI-powered smart eyewear designed to empower blind and low-vision users with hands-free independence. Built on Google Glass, they audibly articulate the world around youâ€”instantly reading text, recognizing faces, and identifying objects or colors. Beyond automated vision, they feature "Ask Envision" to interactively query scanned documents and "Call a Companion" for immediate video support from friends or family.

**Tech stack:**

* Android (Kotlin + Compose UI)
* MVI + Clean Architecture
* Accessibility-first UX
* Custom LLM + tool orchestration

**Impact:**

* Shipped and evolved core accessibility-first flows for reading and visual assistance.
* Led engineering execution with a focus on reliability, performance, and inclusive UX.

**App links:**

* [Google Play](https://play.google.com/store/apps/details?id=com.letsenvision.envisionai)
* [App Store](https://apps.apple.com/us/app/envision-ai/id1268632314)
